# command_processor.py
import re
from thefuzz import fuzz, process
import json

class CommandProcessor:
    def __init__(self):
        self.intents = self.load_intents()
        
        # Try to load NLTK, but handle gracefully if not available
        try:
            from nltk.tokenize import word_tokenize
            from nltk.corpus import stopwords
            self.word_tokenize = word_tokenize
            self.stop_words = set(stopwords.words('english'))
            self.nltk_available = True
        except (ImportError, LookupError) as e:
            print(f"‚ö†Ô∏è NLTK not fully available: {e}")
            self.word_tokenize = lambda x: x.lower().split()
            self.stop_words = {'the', 'a', 'an', 'to', 'in', 'on', 'at', 'for'}
            self.nltk_available = False
        
        # ‚úÖ NEW: Romanization mappings for Kannada commands
        self.kannada_romanization = {
            # Time queries
            "samaya": "‡≤∏‡≤Æ‡≤Ø",
            "samay": "‡≤∏‡≤Æ‡≤Ø",
            "time": "‡≤∏‡≤Æ‡≤Ø",
            "enu": "‡≤è‡≤®‡≥Å",
            "yenu": "‡≤è‡≤®‡≥Å",
            "eenu": "‡≤è‡≤®‡≥Å",
            
            # App commands
            "tere": "‡≤§‡≥Ü‡≤∞‡≥Ü",
            "there": "‡≤§‡≥Ü‡≤∞‡≥Ü",
            "open": "‡≤§‡≥Ü‡≤∞‡≥Ü",
            "muchu": "‡≤Æ‡≥Å‡≤ö‡≥ç‡≤ö‡≥Å",
            "close": "‡≤Æ‡≥Å‡≤ö‡≥ç‡≤ö‡≥Å",
            
            # Calculator
            "calculator": "‡≤ï‡≥ç‡≤Ø‡≤æ‡≤≤‡≥ç‡≤ï‡≥Å‡≤≤‡≥á‡≤ü‡≤∞‡≥ç",
            "calc": "‡≤ï‡≥ç‡≤Ø‡≤æ‡≤≤‡≥ç‡≤ï‡≥Å‡≤≤‡≥á‡≤ü‡≤∞‡≥ç",
            "kalkulater": "‡≤ï‡≥ç‡≤Ø‡≤æ‡≤≤‡≥ç‡≤ï‡≥Å‡≤≤‡≥á‡≤ü‡≤∞‡≥ç",
            
            # Reminders
            "nenapisu": "‡≤®‡≥Ü‡≤®‡≤™‡≤ø‡≤∏‡≥Å",
            "remind": "‡≤®‡≥Ü‡≤®‡≤™‡≤ø‡≤∏‡≥Å",
            "reminder": "‡≤∞‡≤ø‡≤Æ‡≥à‡≤Ç‡≤°‡≤∞‡≥ç",
        }
        
        # ‚úÖ NEW: Hindi romanization mappings
        self.hindi_romanization = {
            "samay": "‡§∏‡§Æ‡§Ø",
            "time": "‡§∏‡§Æ‡§Ø",
            "kya": "‡§ï‡•ç‡§Ø‡§æ",
            "hai": "‡§π‡•à",
            "kholo": "‡§ñ‡•ã‡§≤‡•ã",
            "open": "‡§ñ‡•ã‡§≤‡•ã",
            "band": "‡§¨‡§Ç‡§¶",
            "close": "‡§¨‡§Ç‡§¶",
            "calculator": "‡§ï‡•à‡§≤‡§ï‡•Å‡§≤‡•á‡§ü‡§∞",
            "yaad": "‡§Ø‡§æ‡§¶",
            "remind": "‡§Ø‡§æ‡§¶",
        }
        
    def normalize_romanized_text(self, text, language='en'):
        """
        ‚úÖ NEW: Convert romanized Kannada/Hindi to native script
        Example: "samaya enu" ‚Üí "‡≤∏‡≤Æ‡≤Ø ‡≤è‡≤®‡≥Å"
        """
        if language == 'kn':
            # Normalize Kannada romanization
            words = text.lower().split()
            normalized_words = []
            for word in words:
                # Check if word is romanized
                if word in self.kannada_romanization:
                    normalized_words.append(self.kannada_romanization[word])
                else:
                    normalized_words.append(word)
            return ' '.join(normalized_words)
        
        elif language == 'hi':
            # Normalize Hindi romanization
            words = text.lower().split()
            normalized_words = []
            for word in words:
                if word in self.hindi_romanization:
                    normalized_words.append(self.hindi_romanization[word])
                else:
                    normalized_words.append(word)
            return ' '.join(normalized_words)
        
        return text
    
    def load_intents(self):
        """Define command intents and patterns with multilingual support"""
        return {
            "open_app": {
                "patterns": [
                    r"open\s+(.+)",
                    r"launch\s+(.+)",
                    r"start\s+(.+)",
                    r"run\s+(.+)",
                    r"‡§ñ‡•ã‡§≤‡•ã\s+(.+)",
                    r"‡§∂‡•Å‡§∞‡•Ç ‡§ï‡§∞‡•ã\s+(.+)",
                    r"‡§ö‡§≤‡§æ‡§ì\s+(.+)",
                    r"‡≤§‡≥Ü‡≤∞‡≥Ü\s+(.+)",
                    r"‡≤™‡≥ç‡≤∞‡≤æ‡≤∞‡≤Ç‡≤≠‡≤ø‡≤∏‡≥Å\s+(.+)",
                    # ‚úÖ NEW: Romanized patterns
                    r"tere\s+(.+)",
                    r"there\s+(.+)",
                ],
                "keywords": ["open", "launch", "start", "run", "‡§ñ‡•ã‡§≤‡•ã", "‡§∂‡•Å‡§∞‡•Ç", "‡§ö‡§≤‡§æ‡§ì", "‡≤§‡≥Ü‡≤∞‡≥Ü", "‡≤™‡≥ç‡≤∞‡≤æ‡≤∞‡≤Ç‡≤≠‡≤ø‡≤∏‡≥Å", "tere", "there"]
            },
            "close_app": {
                "patterns": [
                    r"close\s+(.+)",
                    r"quit\s+(.+)",
                    r"exit\s+(.+)",
                    r"stop\s+(.+)",
                    r"‡§¨‡§Ç‡§¶ ‡§ï‡§∞‡•ã\s+(.+)",
                    r"‡§∞‡•ã‡§ï‡•ã\s+(.+)",
                    r"‡≤Æ‡≥Å‡≤ö‡≥ç‡≤ö‡≥Å\s+(.+)",
                    r"‡≤®‡≤ø‡≤≤‡≥ç‡≤≤‡≤ø‡≤∏‡≥Å\s+(.+)",
                    # ‚úÖ NEW: Romanized patterns
                    r"muchu\s+(.+)",
                    r"band\s+(.+)",
                ],
                "keywords": ["close", "quit", "exit", "stop", "‡§¨‡§Ç‡§¶", "‡§∞‡•ã‡§ï‡•ã", "‡≤Æ‡≥Å‡≤ö‡≥ç‡≤ö‡≥Å", "‡≤®‡≤ø‡≤≤‡≥ç‡≤≤‡≤ø‡≤∏‡≥Å", "muchu", "band"]
            },
            "create_reminder": {
                "patterns": [
                    r"remind me to (.+) at (.+)",
                    r"set reminder for (.+)",
                    r"add reminder (.+)",
                    r"‡§Æ‡•Å‡§ù‡•á ‡§Ø‡§æ‡§¶ ‡§¶‡§ø‡§≤‡§æ‡§ì (.+)",
                    r"‡§∞‡§ø‡§Æ‡§æ‡§á‡§Ç‡§°‡§∞ ‡§∏‡•á‡§ü ‡§ï‡§∞‡•ã (.+)",
                    r"‡≤®‡≤®‡≤ó‡≥Ü ‡≤®‡≥Ü‡≤®‡≤™‡≤ø‡≤∏‡≥Å (.+)",
                    r"‡≤∞‡≤ø‡≤Æ‡≥à‡≤Ç‡≤°‡≤∞‡≥ç ‡≤∏‡≥Ü‡≤ü‡≥ç ‡≤Æ‡≤æ‡≤° (.+)",
                    # ‚úÖ NEW: Romanized patterns
                    r"nenapisu (.+)",
                    r"yaad dilao (.+)",
                ],
                "keywords": ["remind", "reminder", "remember", "‡§Ø‡§æ‡§¶", "‡§∞‡§ø‡§Æ‡§æ‡§á‡§Ç‡§°‡§∞", "‡≤®‡≥Ü‡≤®‡≤™‡≤ø‡≤∏‡≥Å", "‡≤∞‡≤ø‡≤Æ‡≥à‡≤Ç‡≤°‡≤∞‡≥ç", "nenapisu", "yaad"]
            },
            "create_event": {
                "patterns": [
                    r"schedule (.+) at (.+)",
                    r"add event (.+)",
                    r"create meeting (.+)",
                    r"‡§Æ‡•Ä‡§ü‡§ø‡§Ç‡§ó ‡§¨‡§®‡§æ‡§ì (.+)",
                    r"‡§á‡§µ‡•á‡§Ç‡§ü ‡§ú‡•ã‡§°‡§º‡•ã (.+)",
                    r"‡≤∏‡≤≠‡≥Ü ‡≤∞‡≤ö‡≤ø‡≤∏‡≥Å (.+)",
                    r"‡≤à‡≤µ‡≥Ü‡≤Ç‡≤ü‡≥ç ‡≤∏‡≥á‡≤∞‡≤ø‡≤∏‡≥Å (.+)",
                ],
                "keywords": ["schedule", "event", "meeting", "appointment", "calendar"]
            },
            "create_note": {
                "patterns": [
                    r"take note (.+)",
                    r"create note (.+)",
                    r"write note (.+)",
                    r"note (.+)",
                    r"‡§®‡•ã‡§ü ‡§¨‡§®‡§æ‡§ì (.+)",
                    r"‡§≤‡§ø‡§ñ‡•ã (.+)",
                    r"‡≤®‡≥ã‡≤ü‡≥ç ‡≤Æ‡≤æ‡≤° (.+)",
                    r"‡≤¨‡≤∞‡≥Ü (.+)",
                ],
                "keywords": ["note", "write", "save"]
            },
            "search_note": {
                "patterns": [
                    r"find note (.+)",
                    r"search note (.+)",
                    r"show notes about (.+)",
                    r"‡§®‡•ã‡§ü ‡§ñ‡•ã‡§ú‡•ã (.+)",
                    r"‡§®‡•ã‡§ü ‡§¶‡§ø‡§ñ‡§æ‡§ì (.+)",
                    r"‡≤®‡≥ã‡≤ü‡≥ç ‡≤π‡≥Å‡≤°‡≥Å‡≤ï‡≥Å (.+)",
                    r"‡≤®‡≥ã‡≤ü‡≥ç ‡≤§‡≥ã‡≤∞‡≤ø‡≤∏‡≥Å (.+)",
                ],
                "keywords": ["find", "search", "show notes"]
            },
            "send_email": {
                "patterns": [
                    r"send email to (.+?) (?:subject|about|saying)?\s*(.+)?",
                    r"email (.+?) (?:about|saying)?\s*(.+)?",
                    r"‡§à‡§Æ‡•á‡§≤ ‡§≠‡•á‡§ú‡•ã (.+)",
                    r"‡§Æ‡•á‡§≤ ‡§ï‡§∞‡•ã (.+)",
                    r"‡≤á‡≤Æ‡≥á‡≤≤‡≥ç ‡≤ï‡≤≥‡≥Å‡≤π‡≤ø‡≤∏‡≥Å (.+)",
                ],
                "keywords": ["send email", "email", "compose"]
            },
            "send_whatsapp": {
                "patterns": [
                    # ‚úÖ FIXED: Better patterns for WhatsApp
                    r"send\s+(.+?)\s+(?:whatsapp|via whatsapp|on whatsapp)\s+to\s+(.+)",
                    r"whatsapp\s+(.+?)\s+to\s+(.+)",
                    r"message\s+(.+?)\s+to\s+(.+?)\s+(?:on|via)?\s*whatsapp",
                    r"send\s+whatsapp\s+(?:message\s+)?to\s+(.+?)\s+saying\s+(.+)",
                    r"‡§µ‡•ç‡§π‡§æ‡§ü‡•ç‡§∏‡§Ö‡§™ (.+?) ‡§ï‡•ã (.+)",
                    r"‡§Æ‡•à‡§∏‡•á‡§ú ‡§ï‡§∞‡•ã (.+)",
                    r"‡≤µ‡≤æ‡≤ü‡≥ç‡≤∏‡≤æ‡≤™‡≥ç ‡≤ï‡≤≥‡≥Å‡≤π‡≤ø‡≤∏‡≥Å (.+)",
                ],
                "keywords": ["whatsapp", "message"]
            },
            "read_pdf": {
                "patterns": [
                    r"read pdf (.+)",
                    r"open pdf (.+)",
                    r"read document (.+)",
                    r"‡§™‡•Ä‡§°‡•Ä‡§è‡§´ ‡§™‡§¢‡§º‡•ã (.+)",
                    r"‡§°‡•â‡§ï‡•ç‡§Ø‡•Å‡§Æ‡•á‡§Ç‡§ü ‡§™‡§¢‡§º‡•ã (.+)",
                    r"‡≤™‡≤ø‡≤°‡≤ø‡≤é‡≤´‡≥ç ‡≤ì‡≤¶‡≥Å (.+)",
                ],
                "keywords": ["read pdf", "read document", "pdf"]
            },
            "get_time": {
                "patterns": [
                    r"what time is it",
                    r"what's the time",
                    r"tell me the time",
                    r"current time",
                    r"‡§∏‡§Æ‡§Ø ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à",
                    r"‡§ü‡§æ‡§á‡§Æ ‡§¨‡§§‡§æ‡§ì",
                    r"‡§Ö‡§≠‡•Ä ‡§ï‡§ø‡§§‡§®‡•á ‡§¨‡§ú‡•á ‡§π‡•à‡§Ç",
                    r"‡≤∏‡≤Æ‡≤Ø ‡≤è‡≤®‡≥Å",
                    r"‡≤ü‡≥à‡≤Æ‡≥ç ‡≤π‡≥á‡≤≥‡≥Å",
                    r"‡≤à‡≤ó ‡≤é‡≤∑‡≥ç‡≤ü‡≥Å ‡≤ó‡≤Ç‡≤ü‡≥Ü",
                    # ‚úÖ NEW: Romanized patterns
                    r"samaya\s+(?:enu|yenu|eenu)",
                    r"samay\s+(?:enu|yenu|kya)",
                    r"time\s+(?:enu|kya|hai)",
                ],
                "keywords": ["time", "clock", "‡§∏‡§Æ‡§Ø", "‡§ü‡§æ‡§á‡§Æ", "‡≤∏‡≤Æ‡≤Ø", "samaya", "samay"]
            },
            "get_date": {
                "patterns": [
                    r"what's the date",
                    r"what day is it",
                    r"tell me the date",
                    r"today's date",
                    r"‡§§‡§æ‡§∞‡•Ä‡§ñ ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à",
                    r"‡§Ü‡§ú ‡§ï‡•Ä ‡§§‡§æ‡§∞‡•Ä‡§ñ",
                    r"‡§ï‡•å‡§® ‡§∏‡§æ ‡§¶‡§ø‡§® ‡§π‡•à",
                    r"‡≤¶‡≤ø‡≤®‡≤æ‡≤Ç‡≤ï ‡≤è‡≤®‡≥Å",
                    r"‡≤á‡≤Ç‡≤¶‡≤ø‡≤® ‡≤¶‡≤ø‡≤®‡≤æ‡≤Ç‡≤ï",
                    r"‡≤Ø‡≤æ‡≤µ ‡≤¶‡≤ø‡≤®",
                ],
                "keywords": ["date", "day", "today", "‡§§‡§æ‡§∞‡•Ä‡§ñ", "‡§¶‡§ø‡§®", "‡≤¶‡≤ø‡≤®‡≤æ‡≤Ç‡≤ï"]
            },
            "get_weather": {
                "patterns": [
                    r"what's the weather",
                    r"weather forecast",
                    r"how's the weather",
                    r"temperature today",
                    r"‡§Æ‡•å‡§∏‡§Æ ‡§ï‡•à‡§∏‡§æ ‡§π‡•à",
                    r"‡§Ü‡§ú ‡§ï‡§æ ‡§Æ‡•å‡§∏‡§Æ",
                    r"‡≤§‡≤æ‡≤™‡≤Æ‡≤æ‡≤® ‡≤é‡≤∑‡≥ç‡≤ü‡≥Å",
                ],
                "keywords": ["weather", "temperature", "forecast"]
            },
            # Add these patterns to the load_intents() method in CommandProcessor class

            "tell_joke": {
                "patterns": [
                    r"tell me a joke",
                    r"tell a joke",
                    r"make me laugh",
                    r"say something funny",
                    r"joke",
                    r"i'm bored",
                    r"i am bored",
                    r"entertain me",
                    r"bore ho gaya",
                    r"bore ho raha",
                    r"‡§Æ‡•Å‡§ù‡•á ‡§¨‡•ã‡§∞ ‡§π‡•ã ‡§∞‡§π‡§æ ‡§π‡•à",
                    r"‡§Æ‡§ú‡§æ ‡§®‡§π‡•Ä‡§Ç ‡§Ü ‡§∞‡§π‡§æ",
                    r"‡§ú‡•ã‡§ï ‡§∏‡•Å‡§®‡§æ‡§ì",
                    r"‡§Æ‡•Å‡§ù‡•á ‡§π‡§Ç‡§∏‡§æ‡§ì",
                    r"‡§ï‡•Å‡§õ ‡§Æ‡§ú‡•á‡§¶‡§æ‡§∞ ‡§¨‡§§‡§æ‡§ì",
                    r"‡≤®‡≤®‡≤ó‡≥Ü ‡≤¨‡≥á‡≤∏‡≤∞‡≤µ‡≤æ‡≤ó‡≤ø‡≤¶‡≥Ü",
                    r"‡≤®‡≤®‡≤ó‡≥Ü ‡≤¨‡≥ã‡≤∞‡≥ç ‡≤Ü‡≤ó‡≤ø‡≤¶‡≥Ü",
                    r"‡≤ú‡≥ã‡≤ï‡≥ç ‡≤π‡≥á‡≤≥‡≥Å",
                    r"‡≤®‡≤®‡≥ç‡≤®‡≤®‡≥ç‡≤®‡≥Å ‡≤®‡≤ó‡≤ø‡≤∏‡≥Å",
                    r"‡≤è‡≤®‡≤æ‡≤¶‡≤∞‡≥Ç ‡≤Æ‡≤ú‡≥á‡≤¶‡≤æ‡≤∞ ‡≤π‡≥á‡≤≥‡≥Å",
                ],
                "keywords": ["joke", "funny", "laugh", "bored", "entertain", "bore", "‡§Æ‡§ú‡§æ", "‡§π‡§Ç‡§∏‡§æ‡§ì", "‡≤Æ‡≤ú‡≥á‡≤¶‡≤æ‡≤∞", "‡≤®‡≤ó‡≤ø‡≤∏‡≥Å"]
            },
            "get_news": {
                "patterns": [
                    r"what's the news",
                    r"latest news",
                    r"news headlines",
                    r"tell me the news",
                    r"‡§®‡•ç‡§Ø‡•Ç‡§ú‡§º ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à",
                    r"‡§∏‡§Æ‡§æ‡§ö‡§æ‡§∞ ‡§∏‡•Å‡§®‡§æ‡§ì",
                    r"‡≤∏‡≥Å‡≤¶‡≥ç‡≤¶‡≤ø ‡≤è‡≤®‡≥Å",
                ],
                "keywords": ["news", "headlines", "latest"]
            },
            "system_command": {
                "patterns": [
                    r"shutdown",
                    r"restart",
                    r"sleep",
                    r"‡§¨‡§Ç‡§¶ ‡§ï‡§∞‡•ã",
                    r"‡§∂‡§ü‡§°‡§æ‡§â‡§®",
                    r"‡§∞‡•Ä‡§∏‡•ç‡§ü‡§æ‡§∞‡•ç‡§ü",
                    r"‡≤∑‡≤ü‡≥ç‚Äå‡≤°‡≥å‡≤®‡≥ç",
                    r"‡≤Æ‡≤∞‡≥Å‡≤™‡≥ç‡≤∞‡≤æ‡≤∞‡≤Ç‡≤≠",
                ],
                "keywords": ["shutdown", "restart", "sleep"]
            }
            
        }
    
    def preprocess_text(self, text):
        """Clean and normalize text"""
        text = text.lower().strip()
        tokens = self.word_tokenize(text)
        
        # Remove stop words but keep important ones for commands
        important_words = {'open', 'close', 'send', 'read', 'create', 'find'}
        tokens = [w for w in tokens if w not in self.stop_words or w in important_words]
        
        return text, tokens
    
    def detect_intent(self, text):
        """Detect command intent using pattern matching and fuzzy matching"""
        original_text, tokens = self.preprocess_text(text)
        
        best_match = {
            "intent": None,
            "confidence": 0,
            "entities": {}
        }
        
        # Pattern matching (highest priority)
        for intent_name, intent_data in self.intents.items():
            for pattern in intent_data["patterns"]:
                match = re.search(pattern, original_text, re.IGNORECASE)
                if match:
                    best_match["intent"] = intent_name
                    best_match["confidence"] = 0.95
                    best_match["entities"] = {f"entity_{i}": (g.strip() if g else "") for i, g in enumerate(match.groups())}
                    return best_match
        
        # Keyword fuzzy matching fallback
        for intent_name, intent_data in self.intents.items():
            for keyword in intent_data["keywords"]:
                ratio = fuzz.partial_ratio(keyword, original_text)
                if ratio > 80 and ratio > best_match["confidence"] * 100:
                    best_match["intent"] = intent_name
                    best_match["confidence"] = ratio / 100
        
        return best_match
    
    def extract_entities(self, text, intent):
        """Extract relevant entities based on intent - FIXED VERSION"""
        entities = {}
        
        if intent in ("open_app", "close_app"):
            # ‚úÖ FIXED: Better app name extraction
            words = text.lower().split()
            action_words = ['open', 'close', 'launch', 'quit', 'start', 'stop', 'exit', 
                           'tere', 'there', 'muchu', 'band', '‡§ñ‡•ã‡§≤‡•ã', '‡§¨‡§Ç‡§¶', '‡≤§‡≥Ü‡≤∞‡≥Ü', '‡≤Æ‡≥Å‡≤ö‡≥ç‡≤ö‡≥Å']
            
            for i, word in enumerate(words):
                if word in action_words and i + 1 < len(words):
                    # Get the next word as app name
                    app_name = words[i + 1]
                    # Remove common suffixes
                    app_name = app_name.replace('.', '').replace(',', '')
                    entities["app_name"] = app_name
                    print(f"üîç Extracted app_name: '{app_name}' from text: '{text}'")
                    break
        
        elif intent == "create_reminder":
            patterns = [
                r"remind me to (.+?)(?: at| on| in)?\s*(.+)?",
                r"‡§Æ‡•Å‡§ù‡•á ‡§Ø‡§æ‡§¶ ‡§¶‡§ø‡§≤‡§æ‡§ì (.+?)(?: ‡§ï‡•ã| ‡§Æ‡•á‡§Ç)?\s*(.+)?",
                r"‡≤®‡≤®‡≤ó‡≥Ü ‡≤®‡≥Ü‡≤®‡≤™‡≤ø‡≤∏‡≥Å (.+?)(?: ‡≤®‡≤≤‡≥ç‡≤≤‡≤ø)?\s*(.+)?",
                r"nenapisu (.+)",
                r"yaad dilao (.+)",
            ]
            for pattern in patterns:
                match = re.search(pattern, text, re.IGNORECASE)
                if match:
                    entities["task"] = match.group(1).strip()
                    entities["time"] = match.group(2).strip() if len(match.groups()) > 1 and match.group(2) else "later"
                    break

        elif intent == "send_email":
            match = re.search(r"to\s+(.+?)(?: saying| about| subject)?\s*(.+)?", text, re.IGNORECASE)
            if match:
                entities["recipient"] = match.group(1).strip()
                entities["content"] = match.group(2).strip() if match.group(2) else ""
        
        elif intent == "send_whatsapp":
            # ‚úÖ FIXED: Better WhatsApp parsing
            # Pattern 1: "send <message> whatsapp to <contact>"
            match = re.search(r"send\s+(.+?)\s+(?:whatsapp|via whatsapp)\s+to\s+(.+)", text, re.IGNORECASE)
            if match:
                entities["message"] = match.group(1).strip()
                entities["contact"] = match.group(2).strip()
                print(f"üîç WhatsApp - contact: '{entities['contact']}', message: '{entities['message']}'")
            else:
                # Pattern 2: "whatsapp <message> to <contact>"
                match = re.search(r"whatsapp\s+(.+?)\s+to\s+(.+)", text, re.IGNORECASE)
                if match:
                    entities["message"] = match.group(1).strip()
                    entities["contact"] = match.group(2).strip()
                    print(f"üîç WhatsApp - contact: '{entities['contact']}', message: '{entities['message']}'")
                else:
                    # Pattern 3: "message <name> on whatsapp <message>"
                    match = re.search(r"message\s+(.+?)\s+on\s+whatsapp\s+(.+)", text, re.IGNORECASE)
                    if match:
                        entities["contact"] = match.group(1).strip()
                        entities["message"] = match.group(2).strip()
                        print(f"üîç WhatsApp - contact: '{entities['contact']}', message: '{entities['message']}'")
        
        elif intent == "get_weather":
            match = re.search(r"weather (?:in|at|for)?\s*([A-Za-z\s]+)", text, re.IGNORECASE)
            if match:
                entities["city"] = match.group(1).strip()
        
        return entities
    
    def process_command(self, text):
        """Main command processing pipeline"""
        original_text = text.strip()
        detection = self.detect_intent(original_text)
        
        result = {
            "intent": detection.get("intent"),
            "confidence": detection.get("confidence", 0),
            "entities": detection.get("entities", {}),
            "original_text": original_text
        }
        
        if result["intent"] and result["confidence"] > 0.6:
            extracted = self.extract_entities(original_text, result["intent"])
            extracted.update(result["entities"])
            result["entities"] = extracted
            return result
        
        return {
            "intent": "unknown",
            "confidence": 0,
            "entities": {},
            "original_text": original_text
        }