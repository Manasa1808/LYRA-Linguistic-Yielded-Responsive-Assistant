# main.py - Clean Architecture: ASR â†’ Command Processor â†’ Feature Modules
# speech â†’ text â†’ intent â†’ feature â†’ system call

from PyQt5.QtWidgets import QApplication, QDialog, QMessageBox
from PyQt5.QtCore import QThread, pyqtSignal
import sys, os
from datetime import datetime, timedelta
import time
import re
import threading

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from gui.main_window import VoiceAssistantGUI
from gui.login_window import LoginWindow
from core.audio_handler import AudioHandler
from core.speech_recognition import SpeechRecognizer
from core.tts_engine import TTSEngine
from core.command_processor import CommandProcessor
from features.app_controller import AppController
from features.utility_features import UtilityFeatures
from auth.profile_manager import ProfileManager
from database.db_manager import DatabaseManager
from features.custom_commands import CustomCommandsManager
from features.reminder_manager import ReminderManager
from features.calendar_manager import CalendarManager
from features.email_handler import EmailHandler
from features.whatsapp_handler import WhatsAppHandler
from features.notes_manager import NotesManager
from auth.face_recognition import FaceRecognition
from config import DEFAULT_LANGUAGE
import torch

# ğŸ”’ Force GPU execution
if not torch.cuda.is_available():
    raise SystemError("âŒ GPU not detected. LYRA requires CUDA to run Whisper models.")

device_name = torch.cuda.get_device_name(0)
torch.backends.cudnn.benchmark = True
print(f"[LYRA] ğŸš€ GPU Ready: {device_name}")

# âœ… FIX: Do NOT set default dtype to float16 - breaks Whisper
# Whisper will use FP16 internally when fp16=True is passed


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# EMOTIONAL ANALYZER CLASS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
class EmotionalAnalyzer:
    """Analyze emotional tone from text input in English, Hindi, and Kannada"""

    def __init__(self):
        self.emotion_keywords = {
            'happy': {
                'en': ['happy', 'great', 'awesome', 'wonderful', 'excited', 'fantastic',
                       'excellent', 'good', 'joy', 'glad', 'amazing', 'perfect', 'love',
                       'thrilled', 'delighted', 'cheerful', 'super', 'yay', 'woohoo'],
                'hi': ['à¤–à¥à¤¶', 'à¤¬à¤¢à¤¼à¤¿à¤¯à¤¾', 'à¤¶à¤¾à¤¨à¤¦à¤¾à¤°', 'à¤…à¤šà¥à¤›à¤¾', 'à¤‰à¤¤à¥à¤¸à¤¾à¤¹à¤¿à¤¤', 'à¤ªà¥à¤°à¤¸à¤¨à¥à¤¨', 'à¤®à¤¸à¥à¤¤',
                       'à¤§à¤¨à¥à¤¯à¤µà¤¾à¤¦', 'à¤…à¤¦à¥à¤­à¥à¤¤', 'à¤®à¤œà¤¾', 'à¤¬à¤¹à¥à¤¤ à¤…à¤šà¥à¤›à¤¾', 'à¤¸à¥à¤–à¥€', 'à¤–à¥à¤¶à¥€'],
                'kn': ['à²¸à²‚à²¤à³‹à²·', 'à²’à²³à³à²³à³†à²¯à²¦à³', 'à²…à²¦à³à²­à³à²¤', 'à²‰à²¤à³à²¤à²®', 'à²¸à²‚à²¤à²¸', 'à²¸à³à²–', 'à²®à³†à²šà³à²šà³',
                       'à²…à²¦à³à²¬à³à²¤', 'à²šà³†à²¨à³à²¨à²¾à²—à²¿à²¦à³†', 'à²–à³à²·à²¿', 'à²°à³‹à²®à²¾à²‚à²šà²•']
            },
            'sad': {
                'en': ['sad', 'unhappy', 'depressed', 'down', 'upset', 'disappointed',
                       'terrible', 'bad', 'awful', 'cry', 'miserable', 'gloomy', 'hurt',
                       'lonely', 'pain', 'sorry', 'worried', 'stressed', 'anxious'],
                'hi': ['à¤¦à¥à¤–à¥€', 'à¤‰à¤¦à¤¾à¤¸', 'à¤–à¤°à¤¾à¤¬', 'à¤¨à¤¿à¤°à¤¾à¤¶', 'à¤ªà¤°à¥‡à¤¶à¤¾à¤¨', 'à¤¬à¥à¤°à¤¾', 'à¤°à¥‹à¤¨à¤¾', 'à¤šà¤¿à¤‚à¤¤à¤¾',
                       'à¤¤à¤•à¤²à¥€à¤«', 'à¤¦à¤°à¥à¤¦', 'à¤…à¤•à¥‡à¤²à¤¾', 'à¤˜à¤¬à¤°à¤¾à¤¹à¤Ÿ', 'à¤¤à¤¨à¤¾à¤µ', 'à¤®à¥à¤¶à¥à¤•à¤¿à¤²'],
                'kn': ['à²¦à³à²ƒà²–', 'à²¨à³Šà²‚à²¦', 'à²•à³†à²Ÿà³à²Ÿà²¦à³à²¦à³', 'à²¨à²¿à²°à²¾à²¶à³†', 'à²šà²¿à²‚à²¤à³†', 'à²¤à³Šà²‚à²¦à²°à³†', 'à²¨à³‹à²µà³',
                       'à²à²•à²¾à²‚à²—à²¿', 'à²•à²·à³à²Ÿ', 'à²¬à³‡à²¸à²°']
            },
            'okay': {
                'en': ['okay', 'ok', 'fine', 'alright', 'average', 'normal', 'so-so',
                       'sure', 'yes', 'yeah', 'right', 'understood', 'got it'],
                'hi': ['à¤ à¥€à¤•', 'à¤“à¤•à¥‡', 'à¤¸à¤¾à¤®à¤¾à¤¨à¥à¤¯', 'à¤šà¤²à¥‡à¤—à¤¾', 'à¤¹à¤¾à¤‚', 'à¤¸à¤®à¤ à¤—à¤¯à¤¾', 'à¤¹à¥‹ à¤—à¤¯à¤¾', 'à¤…à¤šà¥à¤›à¤¾'],
                'kn': ['à²¸à²°à²¿', 'à²“à²•à³†', 'à²šà³†à²¨à³à²¨à²¾à²—à²¿à²¦à³†', 'à²¸à²¾à²®à²¾à²¨à³à²¯', 'à²¹à³Œà²¦à³', 'à²…à²°à³à²¥à²µà²¾à²¯à²¿à²¤à³']
            }
        }

        self.emotion_phrases = {
            'happy': {
                'en': ["i'm happy", "feeling great", "i feel good", "i'm excited", "this is great"],
                'hi': ["à¤®à¥ˆà¤‚ à¤–à¥à¤¶ à¤¹à¥‚à¤‚", "à¤…à¤šà¥à¤›à¤¾ à¤²à¤— à¤°à¤¹à¤¾ à¤¹à¥ˆ", "à¤¬à¤¹à¥à¤¤ à¤…à¤šà¥à¤›à¤¾", "à¤®à¤œà¤¾ à¤† à¤°à¤¹à¤¾"],
                'kn': ["à²¨à²¾à²¨à³ à²¸à²‚à²¤à³‹à²·à²µà²¾à²—à²¿à²¦à³à²¦à³‡à²¨à³†", "à²šà³†à²¨à³à²¨à²¾à²—à²¿ à²…à²¨à²¿à²¸à³à²¤à³à²¤à²¿à²¦à³†", "à²¤à³à²‚à²¬à²¾ à²šà³†à²¨à³à²¨à²¾à²—à²¿à²¦à³†"]
            },
            'sad': {
                'en': ["i'm sad", "feeling down", "not good", "i'm upset", "feeling bad"],
                'hi': ["à¤®à¥ˆà¤‚ à¤¦à¥à¤–à¥€ à¤¹à¥‚à¤‚", "à¤…à¤šà¥à¤›à¤¾ à¤¨à¤¹à¥€à¤‚ à¤²à¤— à¤°à¤¹à¤¾", "à¤ªà¤°à¥‡à¤¶à¤¾à¤¨ à¤¹à¥‚à¤‚", "à¤‰à¤¦à¤¾à¤¸ à¤¹à¥‚à¤‚"],
                'kn': ["à²¨à²¾à²¨à³ à²¦à³à²ƒà²–à²µà²¾à²—à²¿à²¦à³à²¦à³‡à²¨à³†", "à²’à²³à³à²³à³†à²¯à²¦à²¿à²²à³à²²", "à²šà²¿à²‚à²¤à³†à²¯à²¾à²—à²¿à²¦à³†"]
            },
            'okay': {
                'en': ["i'm okay", "it's fine", "alright", "all good"],
                'hi': ["à¤®à¥ˆà¤‚ à¤ à¥€à¤• à¤¹à¥‚à¤‚", "à¤¸à¤¬ à¤ à¥€à¤• à¤¹à¥ˆ", "à¤šà¤²à¥‡à¤—à¤¾"],
                'kn': ["à²¨à²¾à²¨à³ à²¸à²°à²¿à²¯à²¾à²—à²¿à²¦à³à²¦à³‡à²¨à³†", "à²à²²à³à²²à²¾ à²šà³†à²¨à³à²¨à²¾à²—à²¿à²¦à³†"]
            }
        }

    def detect_emotion(self, text):
        """Detect emotion from text - returns: happy, sad, okay, or neutral"""
        text_lower = text.lower().strip()

        for emotion, lang_phrases in self.emotion_phrases.items():
            for lang, phrases in lang_phrases.items():
                for phrase in phrases:
                    if phrase in text_lower:
                        return emotion

        emotion_scores = {'happy': 0, 'sad': 0, 'okay': 0}

        for emotion, lang_keywords in self.emotion_keywords.items():
            for lang, keywords in lang_keywords.items():
                for keyword in keywords:
                    if keyword in text_lower:
                        emotion_scores[emotion] += 1

        max_emotion = max(emotion_scores, key=emotion_scores.get)
        if emotion_scores[max_emotion] > 0:
            return max_emotion

        return 'neutral'

    def get_emotional_response(self, emotion, language='en'):
        """Get appropriate empathetic response based on emotion"""
        responses = {
            'happy': {
                'en': "That's wonderful! I'm so glad to hear that! ğŸ˜Š How can I assist you today?",
                'hi': "à¤¯à¤¹ à¤¬à¤¹à¥à¤¤ à¤…à¤šà¥à¤›à¤¾ à¤¹à¥ˆ! à¤®à¥à¤à¥‡ à¤¯à¤¹ à¤¸à¥à¤¨à¤•à¤° à¤¬à¤¹à¥à¤¤ à¤–à¥à¤¶à¥€ à¤¹à¥à¤ˆ! ğŸ˜Š à¤®à¥ˆà¤‚ à¤†à¤œ à¤†à¤ªà¤•à¥€ à¤•à¥ˆà¤¸à¥‡ à¤®à¤¦à¤¦ à¤•à¤° à¤¸à¤•à¤¤à¤¾ à¤¹à¥‚à¤‚?",
                'kn': "à²…à²¦à³ à²…à²¦à³à²­à³à²¤à²µà²¾à²—à²¿à²¦à³†! à²…à²¦à²¨à³à²¨à³ à²•à³‡à²³à²²à³ à²¨à²¨à²—à³† à²¤à³à²‚à²¬à²¾ à²¸à²‚à²¤à³‹à²·à²µà²¾à²—à²¿à²¦à³†! ğŸ˜Š à²‡à²‚à²¦à³ à²¨à²¾à²¨à³ à²¨à²¿à²®à²—à³† à²¹à³‡à²—à³† à²¸à²¹à²¾à²¯ à²®à²¾à²¡à²¬à²¹à³à²¦à³?"
            },
            'sad': {
                'en': "I'm sorry to hear that. ğŸ˜” I'm here for you. Is there anything I can do to help or cheer you up?",
                'hi': "à¤®à¥à¤à¥‡ à¤¯à¤¹ à¤¸à¥à¤¨à¤•à¤° à¤¦à¥à¤– à¤¹à¥à¤†à¥¤ ğŸ˜” à¤®à¥ˆà¤‚ à¤†à¤ªà¤•à¥‡ à¤²à¤¿à¤ à¤¯à¤¹à¤¾à¤‚ à¤¹à¥‚à¤‚à¥¤ à¤•à¥à¤¯à¤¾ à¤®à¥ˆà¤‚ à¤•à¥à¤› à¤®à¤¦à¤¦ à¤•à¤° à¤¸à¤•à¤¤à¤¾ à¤¹à¥‚à¤‚ à¤¯à¤¾ à¤†à¤ªà¤•à¥‹ à¤–à¥à¤¶ à¤•à¤° à¤¸à¤•à¤¤à¤¾ à¤¹à¥‚à¤‚?",
                'kn': "à²…à²¦à²¨à³à²¨à³ à²•à³‡à²³à²²à³ à²¨à²¨à²—à³† à²µà²¿à²·à²¾à²¦à²µà²¾à²—à²¿à²¦à³†à¥¤ ğŸ˜” à²¨à²¾à²¨à³ à²¨à²¿à²®à²—à²¾à²—à²¿ à²‡à²²à³à²²à²¿à²¦à³à²¦à³‡à²¨à³†à¥¤ à²¨à²¾à²¨à³ à²à²¨à²¾à²¦à²°à³‚ à²¸à²¹à²¾à²¯ à²®à²¾à²¡à²¬à²¹à³à²¦à³‡ à²…à²¥à²µà²¾ à²¨à²¿à²®à³à²®à²¨à³à²¨à³ à²¸à²‚à²¤à³‹à²·à²ªà²¡à²¿à²¸à²¬à²¹à³à²¦à³‡?"
            },
            'okay': {
                'en': "Okay, got it. ğŸ‘ What would you like me to do for you?",
                'hi': "à¤ à¥€à¤• à¤¹à¥ˆ, à¤¸à¤®à¤ à¤—à¤¯à¤¾à¥¤ ğŸ‘ à¤†à¤ª à¤šà¤¾à¤¹à¤¤à¥‡ à¤¹à¥ˆà¤‚ à¤•à¤¿ à¤®à¥ˆà¤‚ à¤†à¤ªà¤•à¥‡ à¤²à¤¿à¤ à¤•à¥à¤¯à¤¾ à¤•à¤°à¥‚à¤‚?",
                'kn': "à²¸à²°à²¿, à²…à²°à³à²¥à²µà²¾à²¯à²¿à²¤à³à¥¤ ğŸ‘ à²¨à²¾à²¨à³ à²¨à²¿à²®à²—à²¾à²—à²¿ à²à²¨à³ à²®à²¾à²¡à²¬à³‡à²•à³†à²‚à²¦à³ à²¬à²¯à²¸à³à²¤à³à²¤à³€à²°à²¿?"
            },
            'neutral': {
                'en': "I'm listening. How can I help you?",
                'hi': "à¤®à¥ˆà¤‚ à¤¸à¥à¤¨ à¤°à¤¹à¤¾ à¤¹à¥‚à¤‚à¥¤ à¤®à¥ˆà¤‚ à¤†à¤ªà¤•à¥€ à¤•à¥ˆà¤¸à¥‡ à¤®à¤¦à¤¦ à¤•à¤° à¤¸à¤•à¤¤à¤¾ à¤¹à¥‚à¤‚?",
                'kn': "à²¨à²¾à²¨à³ à²•à³‡à²³à³à²¤à³à²¤à²¿à²¦à³à²¦à³‡à²¨à³†à¥¤ à²¨à²¾à²¨à³ à²¨à²¿à²®à²—à³† à²¹à³‡à²—à³† à²¸à²¹à²¾à²¯ à²®à²¾à²¡à²¬à²¹à³à²¦à³?"
            }
        }

        return responses.get(emotion, responses['neutral']).get(language, responses[emotion]['en'])


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAIN VOICE ASSISTANT CLASS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
class VoiceAssistant:
    def __init__(self, username="User", profile_manager=None, db_manager=None, gui=None):
        self.current_user = username
        self.profile_manager = profile_manager
        self.db = db_manager
        self.gui = gui
        self.current_language = DEFAULT_LANGUAGE

        # Core modules
        self.audio_handler = AudioHandler()
        self.speech_recognizer = SpeechRecognizer()
        self.tts = TTSEngine()
        self.command_processor = CommandProcessor()
        self.emotion_analyzer = EmotionalAnalyzer()

        # Feature modules
        self.app_controller = AppController()
        self.utils = UtilityFeatures()
        self.custom_commands = CustomCommandsManager(self.db)

        # Features
        self.reminder_manager = ReminderManager(self.db)
        self.calendar_manager = CalendarManager(self.db)
        self.notes_manager = NotesManager(self.db)
        self.email_handler = EmailHandler()
        self.whatsapp_handler = WhatsAppHandler()

        # State management
        self.assistant_state = "ready"
        self.is_continuous_listening = False
        self.state_lock = threading.Lock()
        self.mic_enabled = True
        self.mode = "PASSIVE"
        
        # Thread for processing audio segments
        self.processing_thread = None
        self.stop_processing = threading.Event()

        if self.gui:
            self._start_gui_reminder_listener()

    def _is_noise_or_unintended(self, text):
        """Check if text appears to be noise or unintended speech"""
        text = text.lower().strip()

        noise_patterns = [
            r'^[uhm]+$',
            r'^[a-z]\s*$',
            r'^\W+$',
            r'^(ha|haha|hehe|lol)+$',
            r'^\d+\s*\d*$',
            r'^(yes|no|okay|ok|yeah|yep|sure|right|wrong)$',
        ]

        for pattern in noise_patterns:
            if re.match(pattern, text, re.IGNORECASE):
                return True

        words = text.split()
        if len(words) <= 2 and len(text) < 10:
            command_starters = ['open', 'close', 'play', 'stop', 'show', 'tell', 'what', 'how', 'when', 'where']
            if not any(word in command_starters for word in words):
                return True

        return False

    def set_language(self, language):
        """Set the current language"""
        self.current_language = language
        
        # âœ… NEW: Tell Whisper about language preference
        if hasattr(self.speech_recognizer, 'set_preferred_language'):
            self.speech_recognizer.set_preferred_language(language)
        
        if self.gui:
            self.gui.update_language_display(language)

    def _start_gui_reminder_listener(self):
        """Background thread for reminder notifications"""
        def listener():
            while True:
                try:
                    user_id = getattr(self.profile_manager, "current_user_id", None)
                    if not user_id:
                        time.sleep(5)
                        continue

                    now = datetime.now()
                    reminders = self.reminder_manager.get_due_reminders(user_id, now)

                    for rem in reminders:
                        msg = f"â° Reminder: {rem['title']}"
                        if rem['description']:
                            msg += f" - {rem['description']}"

                        if self.gui:
                            self.gui.reminder_signal.emit(msg)

                        self.reminder_manager.mark_notified(rem["reminder_id"])

                    time.sleep(10)

                except Exception as e:
                    print(f"Reminder Listener Error: {e}")
                    time.sleep(10)

        threading.Thread(target=listener, daemon=True).start()

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # âœ… CONTINUOUS LISTENING WITH QUEUE-BASED AUDIO PROCESSING
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def start_continuous_listening(self):
        """Start continuous listening mode using queue-based audio capture"""
        if self.is_continuous_listening:
            print("[LYRA] Already in continuous listening mode")
            return
            
        self.is_continuous_listening = True
        self.stop_processing.clear()
        
        # Start audio capture thread (VAD-based segmentation)
        self.audio_handler.start_listening()
        
        # Start processing thread (consumes audio segments from queue)
        self.processing_thread = threading.Thread(target=self._audio_processing_loop, daemon=True)
        self.processing_thread.start()
        
        with self.state_lock:
            self.assistant_state = "ready"
        
        if self.gui:
            self.gui.update_state_signal.emit("ready")
        
        print("[LYRA] âœ… Continuous listening started - Queue-based audio processing")

    def _audio_processing_loop(self):
        """Main loop that processes audio segments from the queue"""
        print("[LYRA] ğŸ§ Audio processing loop started")
        
        while not self.stop_processing.is_set():
            try:
                # Get next audio segment from queue (blocks with timeout)
                audio_segment = self.audio_handler.get_next_audio_segment(timeout=1)
                
                if audio_segment is None:
                    continue
                
                # Check if we're ready to process
                with self.state_lock:
                    if self.assistant_state != "ready":
                        print("[LYRA] â¸ï¸ Not ready, skipping segment")
                        continue
                    
                    # Transition to listening state
                    self.assistant_state = "listening"
                
                if self.gui:
                    self.gui.update_state_signal.emit("listening")
                
                print("[LYRA] ğŸ¤ Processing audio segment...")
                
                # Process the audio segment
                self._process_audio_segment(audio_segment)
                
            except Exception as e:
                print(f"[LYRA] âŒ Error in processing loop: {e}")
                import traceback
                traceback.print_exc()
                
                # Reset to ready state
                with self.state_lock:
                    self.assistant_state = "ready"
                if self.gui:
                    self.gui.update_state_signal.emit("ready")
        
        print("[LYRA] ğŸ›‘ Audio processing loop stopped")

    def _process_audio_segment(self, audio_data):
        """Process audio with Alexa-like conversational fluency"""
        try:
            if not self.speech_recognizer.is_loaded():
                print("[LYRA] âš ï¸ Whisper not loaded yet")
                with self.state_lock:
                    self.assistant_state = "ready"
                if self.gui:
                    self.gui.update_state_signal.emit("ready")
                return

            print("[LYRA] ğŸ§  Transcribing...")
            
            # Transcribe without forcing language (let Whisper detect)
            result = self.speech_recognizer.transcribe(audio_data, language=None)
            
            command_text = result.get('text', '').strip()
            detected_language = result.get('language', 'en')
            confidence = result.get('confidence', 0.0)
            model_used = result.get('model', 'unknown')

            print(f"[LYRA] ğŸ“ {detected_language} | {model_used} | {confidence:.2f}")
            
            if command_text:
                print(f"[LYRA] ğŸ’¬ '{command_text}'")

            # Filter: minimum length and confidence
            min_length = 2 if detected_language == 'en' else 1
            min_conf = 0.18 if detected_language in ['kn', 'hi'] else 0.22
            
            if (command_text and 
                len(command_text) > min_length and
                confidence > min_conf and
                not self._is_noise_or_unintended(command_text)):

                # âœ… Alexa-like flow: Quick acknowledgment
                if self.gui:
                    self.gui.add_message_signal.emit("You", command_text)

                with self.state_lock:
                    self.assistant_state = "talking"
                if self.gui:
                    self.gui.update_state_signal.emit("talking")

                try:
                    # Process command
                    response = self.process_text(command_text, language=detected_language)
                    
                    if not response:
                        # Natural fallback responses
                        fallbacks = {
                            "en": "I'm not sure how to help with that.",
                            "hi": "à¤®à¥à¤à¥‡ à¤¸à¤®à¤ à¤¨à¤¹à¥€à¤‚ à¤†à¤¯à¤¾à¥¤",
                            "kn": "à²¨à²¨à²—à³† à²…à²°à³à²¥à²µà²¾à²—à²²à²¿à²²à³à²²à¥¤"
                        }
                        response = fallbacks.get(detected_language, fallbacks["en"])
                    
                    print(f"[LYRA] ğŸ’¡ {response}")
                except Exception as e:
                    print(f"[LYRA] âŒ {e}")
                    errors = {
                        "en": "Sorry, I encountered an error.",
                        "hi": "à¤•à¥à¤·à¤®à¤¾ à¤•à¤°à¥‡à¤‚, à¤•à¥à¤› à¤—à¤¡à¤¼à¤¬à¤¡à¤¼ à¤¹à¥‹ à¤—à¤ˆà¥¤",
                        "kn": "à²•à³à²·à²®à²¿à²¸à²¿, à²¦à³‹à²· à²¸à²‚à²­à²µà²¿à²¸à²¿à²¦à³†à¥¤"
                    }
                    response = errors.get(detected_language, errors["en"])

                # Display and speak response
                if self.gui:
                    self.gui.add_message_signal.emit("LYRA", response)

                try:
                    self.tts.set_language(detected_language)
                    self.tts.speak(response)
                except Exception as tts_error:
                    print(f"[LYRA] ğŸ”‡ TTS error: {tts_error}")

                time.sleep(1.2)  # Brief pause for natural flow

            else:
                # Silently filter noise
                if command_text:
                    reasons = []
                    if len(command_text) <= min_length:
                        reasons.append("short")
                    if confidence <= min_conf:
                        reasons.append(f"conf:{confidence:.2f}")
                    if self._is_noise_or_unintended(command_text):
                        reasons.append("noise")
                    
                    if reasons:
                        print(f"[LYRA] ğŸ”‡ Filtered ({', '.join(reasons)})")

            # Return to ready
            with self.state_lock:
                self.assistant_state = "ready"
            if self.gui:
                self.gui.update_state_signal.emit("ready")

        except Exception as e:
            print(f"[LYRA] âŒ {e}")
            import traceback
            traceback.print_exc()

            with self.state_lock:
                self.assistant_state = "ready"
            if self.gui:
                self.gui.update_state_signal.emit("ready")

    def stop_continuous_listening(self):
        """Stop continuous listening mode"""
        self.is_continuous_listening = False
        self.stop_processing.set()
        
        # Stop audio handler
        self.audio_handler.stop_continuous_recording()
        
        # Wait for processing thread to finish
        if self.processing_thread:
            self.processing_thread.join(timeout=2)
            self.processing_thread = None

        with self.state_lock:
            self.assistant_state = "ready"

        if self.gui:
            self.gui.update_state_signal.emit("ready")

        print("[LYRA] ğŸ›‘ Continuous listening stopped")

    def _detect_language_unicode(self, text):
        """Detect language using Unicode ranges"""
        text = text.strip()
        if not text:
            return 'en'

        kannada_count = 0
        hindi_count = 0
        english_count = 0

        for char in text:
            code = ord(char)
            if 0x0C80 <= code <= 0x0CFF:
                kannada_count += 1
            elif 0x0900 <= code <= 0x097F:
                hindi_count += 1
            elif ord('a') <= code <= ord('z') or ord('A') <= code <= ord('Z'):
                english_count += 1

        max_count = max(kannada_count, hindi_count, english_count)

        if max_count == 0:
            return 'en'
        elif kannada_count == max_count:
            return 'kn'
        elif hindi_count == max_count:
            return 'hi'
        else:
            return 'en'

    def process_text(self, text, language=None):
        """Process text command"""
        user_id = getattr(self.profile_manager, "current_user_id", None)
        lang = language or self.current_language

        original_text = text.strip()
        detected_lang = self._detect_language_unicode(original_text)

        processing_text = original_text

        if detected_lang != 'en':
            try:
                from core.translation_engine import get_translation_engine
                translator = get_translation_engine()

                if translator.is_available():
                    processing_text = translator.translate_to_english(original_text, detected_lang)
                    print(f"ğŸ”„ Translation: {detected_lang} -> en")
                else:
                    print(f"âš ï¸ Translation unavailable")
                    processing_text = original_text

            except Exception as e:
                print(f"âš ï¸ Translation error: {e}")
                processing_text = original_text

        emotion = self.emotion_analyzer.detect_emotion(processing_text)

        if emotion != 'neutral' and len(processing_text.split()) < 15:
            is_command = False

            cmd_result = self.command_processor.process_command(processing_text)
            if cmd_result.get('intent') and cmd_result.get('confidence', 0) > 0.6:
                is_command = True

            if not is_command:
                response = self.emotion_analyzer.get_emotional_response(emotion, detected_lang)
                if detected_lang != 'en':
                    try:
                        from core.translation_engine import get_translation_engine
                        translator = get_translation_engine()
                        if translator.is_available():
                            response = translator.translate_from_english(response, detected_lang)
                    except Exception:
                        pass
                return response

        if self.custom_commands and user_id:
            custom_cmd = self.custom_commands.match_custom_command(user_id, processing_text)
            if custom_cmd:
                success, result = self.custom_commands.execute_custom_command(custom_cmd)
                if success and isinstance(result, str):
                    if detected_lang != 'en':
                        try:
                            from core.translation_engine import get_translation_engine
                            translator = get_translation_engine()
                            if translator.is_available():
                                result = translator.translate_from_english(result, detected_lang)
                        except Exception:
                            pass
                    return result

        cmd_result = self.command_processor.process_command(processing_text)
        response = self.route_to_feature_module(cmd_result, detected_lang)

        if detected_lang != 'en' and response:
            try:
                from core.translation_engine import get_translation_engine
                translator = get_translation_engine()
                if translator.is_available():
                    response = translator.translate_from_english(response, detected_lang)
            except Exception as e:
                print(f"âš ï¸ Response translation failed: {e}")

        if detected_lang != 'en':
            self.tts.set_language(detected_lang)

        return response

    def route_to_feature_module(self, cmd_result, language=None):
        """Route detected intent to appropriate feature module - COMPLETE VERSION"""
        intent = cmd_result.get('intent')
        entities = cmd_result.get('entities', {})
        user_id = getattr(self.profile_manager, "current_user_id", None)
        lang = language or self.current_language
        original_text = cmd_result.get('original_text', '')

        if intent == 'get_time':
            return self.utils.get_current_time(lang)

        elif intent == 'get_date':
            return self.utils.get_current_date(lang)

        elif intent == 'get_weather':
            city = entities.get('city', 'Bengaluru')
            return self.utils.get_weather(city, lang)

        elif intent == 'tell_joke':
            # Check if it's a "bored" or "entertain me" request
            bored_keywords = ['bored', 'bore', 'entertain', 'à¤¬à¥‹à¤°', 'à¤®à¤œà¤¾', 'à²¬à³‹à²°à³', 'à²®à²œà³‡à²¦à²¾à²°']
            if any(keyword in original_text.lower() for keyword in bored_keywords):
                return self.utils.entertain_me(lang)
            else:
                return self.utils.tell_joke(lang)

        elif intent == 'get_news':
            return self.utils.get_news(lang)

        elif intent == 'open_app':
            app_name = entities.get('app_name', entities.get('entity_0', ''))
            print(f"ğŸ“± Opening app: '{app_name}'")
            if app_name:
                success, msg = self.app_controller.open_app(app_name)
                return msg
            return {
                'en': "Which app would you like me to open?",
                'hi': "à¤•à¥Œà¤¨ à¤¸à¤¾ à¤à¤ª à¤–à¥‹à¤²à¥‚à¤‚?",
                'kn': "à²¯à²¾à²µ à²†à³à²¯à²ªà³ à²¤à³†à²°à³†à²¯à²²à²¿?"
            }.get(lang, "Which app would you like me to open?")

        elif intent == 'close_app':
            app_name = entities.get('app_name', entities.get('entity_0', ''))
            print(f"ğŸ“± Closing app: '{app_name}'")
            if app_name:
                success, msg = self.app_controller.close_app(app_name)
                return msg
            return {
                'en': "Which app would you like me to close?",
                'hi': "à¤•à¥Œà¤¨ à¤¸à¤¾ à¤à¤ª à¤¬à¤‚à¤¦ à¤•à¤°à¥‚à¤‚?",
                'kn': "à²¯à²¾à²µ à²†à³à²¯à²ªà³ à²®à³à²šà³à²šà²²à²¿?"
            }.get(lang, "Which app would you like me to close?")

        elif intent == 'create_reminder' and user_id:
            task = entities.get('task') or entities.get('entity_0') or "Reminder"
            time_text = entities.get('time') or entities.get('entity_1') or "later"
            due_time = self.reminder_manager.parse_reminder_time(f"{task} at {time_text}")
            self.reminder_manager.create_reminder(user_id, task, due_datetime=due_time)
            
            responses = {
                'en': f"Reminder set: {task} at {due_time.strftime('%I:%M %p, %d-%b-%Y')}",
                'hi': f"à¤°à¤¿à¤®à¤¾à¤‡à¤‚à¤¡à¤° à¤¸à¥‡à¤Ÿ à¤•à¤¿à¤¯à¤¾ à¤—à¤¯à¤¾: {task} {due_time.strftime('%I:%M %p, %d-%b-%Y')} à¤ªà¤°",
                'kn': f"à²œà³à²à²¾à²ªà²¨à³† à²¸à³†à²Ÿà³ à²®à²¾à²¡à²²à²¾à²—à²¿à²¦à³†: {task} {due_time.strftime('%I:%M %p, %d-%b-%Y')}"
            }
            return responses.get(lang, responses['en'])

        elif intent == 'create_note' and user_id:
            content = entities.get('entity_0', '')
            if content:
                success, msg = self.notes_manager.create_note(user_id, "Quick Note", content, language=lang)
                return msg
            return {
                'en': "What would you like to note down?",
                'hi': "à¤†à¤ª à¤•à¥à¤¯à¤¾ à¤²à¤¿à¤–à¤¨à¤¾ à¤šà¤¾à¤¹à¤¤à¥‡ à¤¹à¥ˆà¤‚?",
                'kn': "à²¨à³€à²µà³ à²à²¨à³ à²¬à²°à³†à²¯à²²à³ à²¬à²¯à²¸à³à²¤à³à²¤à³€à²°à²¿?"
            }.get(lang, "What would you like to note down?")

        elif intent == 'search_note' and user_id:
            search_term = entities.get('entity_0', '')
            if search_term:
                success, msg, notes = self.notes_manager.search_notes(user_id, search_term, language=lang)
                if success and notes:
                    # Return first few notes
                    note_titles = [note['title'] for note in notes[:3]]
                    titles_str = ', '.join(note_titles)
                    return f"{msg}. {titles_str}"
                return msg
            return {
                'en': "What notes are you looking for?",
                'hi': "à¤†à¤ª à¤•à¥Œà¤¨ à¤¸à¥‡ à¤¨à¥‹à¤Ÿ à¤–à¥‹à¤œ à¤°à¤¹à¥‡ à¤¹à¥ˆà¤‚?",
                'kn': "à²¨à³€à²µà³ à²¯à²¾à²µ à²¨à³‹à²Ÿà³â€Œà²—à²³à²¨à³à²¨à³ à²¹à³à²¡à³à²•à³à²¤à³à²¤à²¿à²¦à³à²¦à³€à²°à²¿?"
            }.get(lang, "What notes are you looking for?")

        elif intent == 'create_event' and user_id:
            title = entities.get('entity_0', 'Event')
            time_str = original_text
            
            print(f"ğŸ“… Creating event: '{title}' from text: '{time_str}'")
            
            # Open calendar
            try:
                success, msg = self.calendar_manager.open_calendar()
            except:
                pass
            
            # Save to database with proper datetime parsing
            try:
                success, msg = self.calendar_manager.create_event(
                    user_id, 
                    title, 
                    start_datetime=time_str,
                    language=lang
                )
                return msg
            except Exception as e:
                print(f"âš ï¸ Calendar error: {e}")
                responses = {
                    'en': f"Opening calendar to create: {title}",
                    'hi': f"à¤•à¥ˆà¤²à¥‡à¤‚à¤¡à¤° à¤–à¥‹à¤² à¤°à¤¹à¥‡ à¤¹à¥ˆà¤‚: {title}",
                    'kn': f"à²•à³à²¯à²¾à²²à³†à²‚à²¡à²°à³ à²¤à³†à²°à³†à²¯à³à²¤à³à²¤à²¿à²¦à³†: {title}"
                }
                return responses.get(lang, responses['en'])

        elif intent == 'send_email':
            recipient = entities.get('recipient', entities.get('entity_0', ''))
            content = entities.get('content', entities.get('entity_1', ''))
            if recipient:
                success, msg = self.email_handler.send_email(recipient, "Message from LYRA", content)
                return msg
            return {
                'en': "Who would you like to send an email to?",
                'hi': "à¤•à¤¿à¤¸à¤•à¥‹ à¤ˆà¤®à¥‡à¤² à¤­à¥‡à¤œà¤¨à¤¾ à¤¹à¥ˆ?",
                'kn': "à²¯à²¾à²°à²¿à²—à³† à²‡à²®à³‡à²²à³ à²•à²³à³à²¹à²¿à²¸à²¬à³‡à²•à³?"
            }.get(lang, "Who would you like to send an email to?")

        elif intent == 'send_whatsapp':
            contact = entities.get('contact', entities.get('entity_1', ''))
            message = entities.get('message', entities.get('entity_0', 'Hello from LYRA!'))
            
            print(f"ğŸ“± WhatsApp - Contact: '{contact}', Message: '{message}'")
            
            if contact:
                success, msg = self.whatsapp_handler.send_message(contact, message)
                return msg
            return {
                'en': "Who would you like to send a WhatsApp message to?",
                'hi': "à¤•à¤¿à¤¸à¤•à¥‹ à¤µà¥à¤¹à¤¾à¤Ÿà¥à¤¸à¤à¤ª à¤­à¥‡à¤œà¤¨à¤¾ à¤¹à¥ˆ?",
                'kn': "à²¯à²¾à²°à²¿à²—à³† à²µà²¾à²Ÿà³à²¸à²ªà³ à²•à²³à³à²¹à²¿à²¸à²¬à³‡à²•à³?"
            }.get(lang, "Who would you like to send a WhatsApp message to?")

        elif intent == 'read_pdf':
            file_path = entities.get('entity_0', '')
            if file_path:
                # Initialize PDF reader
                from features.pdf_reader import PDFReader
                pdf_reader = PDFReader()
                success, content = pdf_reader.read_pdf_summary(file_path, max_chars=500, language=lang)
                return content
            return {
                'en': "Which PDF file would you like me to read?",
                'hi': "à¤•à¥Œà¤¨ à¤¸à¥€ à¤ªà¥€à¤¡à¥€à¤à¤« à¤«à¤¾à¤‡à¤² à¤ªà¤¢à¤¼à¥‚à¤‚?",
                'kn': "à²¯à²¾à²µ à²ªà²¿à²¡à²¿à²à²«à³ à²«à³ˆà²²à³ à²“à²¦à²²à²¿?"
            }.get(lang, "Which PDF file would you like me to read?")

        # Conversational fallback
        else:
            # Check if it's a greeting
            greetings = ['hello', 'hi', 'hey', 'namaste', 'namaskar', 'namaskara', 'hola']
            if any(g in original_text.lower() for g in greetings):
                responses = {
                    'en': "Hello! How can I help you today?",
                    'hi': "à¤¨à¤®à¤¸à¥à¤¤à¥‡! à¤®à¥ˆà¤‚ à¤†à¤ªà¤•à¥€ à¤•à¥ˆà¤¸à¥‡ à¤®à¤¦à¤¦ à¤•à¤° à¤¸à¤•à¤¤à¤¾ à¤¹à¥‚à¤‚?",
                    'kn': "à²¨à²®à²¸à³à²•à²¾à²°! à²¨à²¾à²¨à³ à²¨à²¿à²®à²—à³† à²¹à³‡à²—à³† à²¸à²¹à²¾à²¯ à²®à²¾à²¡à²¬à²¹à³à²¦à³?"
                }
                return responses.get(lang, responses['en'])
            
            # Check if asking about capabilities
            capability_words = ['what can you do', 'help', 'capabilities', 'functions', 'features']
            if any(w in original_text.lower() for w in capability_words):
                responses = {
                    'en': "I can help with time, weather, opening apps, reminders, notes, calendar, WhatsApp, email, jokes, and more. Just ask!",
                    'hi': "à¤®à¥ˆà¤‚ à¤¸à¤®à¤¯, à¤®à¥Œà¤¸à¤®, à¤à¤ªà¥à¤¸ à¤–à¥‹à¤²à¤¨à¥‡, à¤°à¤¿à¤®à¤¾à¤‡à¤‚à¤¡à¤°, à¤¨à¥‹à¤Ÿà¥à¤¸, à¤•à¥ˆà¤²à¥‡à¤‚à¤¡à¤°, à¤µà¥à¤¹à¤¾à¤Ÿà¥à¤¸à¤à¤ª, à¤ˆà¤®à¥‡à¤², à¤œà¥‹à¤•à¥à¤¸ à¤”à¤° à¤¬à¤¹à¥à¤¤ à¤•à¥à¤› à¤®à¥‡à¤‚ à¤®à¤¦à¤¦ à¤•à¤° à¤¸à¤•à¤¤à¤¾ à¤¹à¥‚à¤‚à¥¤",
                    'kn': "à²¨à²¾à²¨à³ à²¸à²®à²¯, à²¹à²µà²¾à²®à²¾à²¨, à²…à²ªà³à²²à²¿à²•à³‡à²¶à²¨à³â€Œà²—à²³à³, à²œà³à²à²¾à²ªà²¨à³†à²—à²³à³, à²¨à³‹à²Ÿà³â€Œà²—à²³à³, à²•à³à²¯à²¾à²²à³†à²‚à²¡à²°à³, à²µà²¾à²Ÿà³à²¸à²ªà³, à²‡à²®à³‡à²²à³, à²¹à²¾à²¸à³à²¯à²—à²³à³ à²®à²¤à³à²¤à³ à²¹à³†à²šà³à²šà²¿à²¨à²¦à²¨à³à²¨à³ à²®à²¾à²¡à²¬à²²à³à²²à³†."
                }
                return responses.get(lang, responses['en'])
            
            # Default: didn't understand
            responses = {
                'en': "I didn't quite catch that. Could you try rephrasing?",
                'hi': "à¤®à¥à¤à¥‡ à¤¸à¤®à¤ à¤¨à¤¹à¥€à¤‚ à¤†à¤¯à¤¾à¥¤ à¤•à¥à¤¯à¤¾ à¤†à¤ª à¤¦à¥‚à¤¸à¤°à¥‡ à¤¤à¤°à¥€à¤•à¥‡ à¤¸à¥‡ à¤•à¤¹ à¤¸à¤•à¤¤à¥‡ à¤¹à¥ˆà¤‚?",
                'kn': "à²¨à²¨à²—à³† à²…à²°à³à²¥à²µà²¾à²—à²²à²¿à²²à³à²²à¥¤ à²¦à²¯à²µà²¿à²Ÿà³à²Ÿà³ à²®à²¤à³à²¤à³† à²¹à³‡à²³à²¬à²¹à³à²¦à³‡?"
            }
            return responses.get(lang, responses['en'])

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# WHISPER LOADER THREAD
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
class WhisperLoaderThread(QThread):
    """Background thread to load Whisper models"""
    finished = pyqtSignal()
    error = pyqtSignal(str)

    def __init__(self, speech_recognizer):
        super().__init__()
        self.speech_recognizer = speech_recognizer

    def run(self):
        """Models are already loaded in __init__, just signal completion"""
        try:
            if self.speech_recognizer.is_loaded():
                print("[LYRA] âœ… All Whisper models already loaded on GPU")
            self.finished.emit()
        except Exception as e:
            self.error.emit(str(e))


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAIN FUNCTION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def main():
    print("=" * 80)
    print("ğŸ¤ LYRA - Linguistic Yielded Responsive Assistant")
    print("=" * 80)
    print("\nâœ… FEATURES:")
    print("   1. Continuous VAD-based audio capture")
    print("   2. GPU Whisper (tiny â†’ base/medium)")
    print("   3. Multi-language support (EN/HI/KN)")
    print("=" * 80 + "\n")

    app = QApplication(sys.argv)

    db = DatabaseManager()
    profile_mgr = ProfileManager()

    try:
        face_rec = FaceRecognition()
        print("âœ… Face recognition initialized")
    except Exception as e:
        print(f"âš ï¸ Face recognition failed: {e}")
        face_rec = None

    login_window = LoginWindow(face_rec)
    if login_window.exec_() != QDialog.Accepted:
        print("âŒ Login cancelled")
        return

    username = login_window.get_authenticated_user()
    if not username:
        print("âŒ No authenticated user")
        QMessageBox.warning(None, "Login Error", "Authentication failed.")
        return

    print(f"âœ… User: {username}")

    success, preferences = profile_mgr.login(username)
    if not success:
        print(f"âš ï¸ Failed to load profile for {username}")

    main_window = VoiceAssistantGUI(None)
    assistant = VoiceAssistant(username, profile_mgr, db, gui=main_window)
    main_window.assistant = assistant

    main_window.show()

    main_window.add_message("LYRA", "ğŸ”„ Loading Whisper models...")
    main_window.statusBar().showMessage("Loading Whisper...")
    QApplication.processEvents()

    def on_whisper_loaded():
        """Called when Whisper finishes loading"""
        print("âœ… Whisper models loaded on GPU")
        main_window.statusBar().showMessage("Ready")

        greeting = f"Welcome {username}. I'm LYRA. Continuous listening is active!"
        main_window.add_message("LYRA", greeting)
        
        try:
            assistant.tts.speak(greeting)
        except Exception as e:
            print(f"âš ï¸ TTS error: {e}")

        print("\nğŸ¤ Starting continuous listening...")
        try:
            assistant.start_continuous_listening()
            main_window.set_continuous_mode(True)
            print("âœ… Continuous listening active!\n")
        except Exception as e:
            print(f"âš ï¸ Could not start continuous listening: {e}\n")

    def on_whisper_error(error_msg):
        """Called if Whisper loading fails"""
        print(f"âŒ Whisper failed: {error_msg}")
        main_window.statusBar().showMessage("Speech recognition unavailable")
        main_window.add_message("LYRA", f"âš ï¸ Speech recognition failed: {error_msg}")

    loader_thread = WhisperLoaderThread(assistant.speech_recognizer)
    loader_thread.finished.connect(on_whisper_loaded)
    loader_thread.error.connect(on_whisper_error)
    loader_thread.start()

    print("=" * 80)
    print("ğŸš€ LYRA ready!")
    print("=" * 80 + "\n")

    sys.exit(app.exec_())


if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"\nâŒ Fatal error: {e}")
        import traceback
        traceback.print_exc()
        input("\nPress Enter to exit...")